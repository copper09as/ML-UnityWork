{
    "name": "root",
    "gauges": {
        "CharacterBBehavior.Policy.Entropy.mean": {
            "value": 2.9679577350616455,
            "min": 2.8900232315063477,
            "max": 3.1596570014953613,
            "count": 167
        },
        "CharacterBBehavior.Policy.Entropy.sum": {
            "value": 569.847900390625,
            "min": 447.2928771972656,
            "max": 811.5856323242188,
            "count": 167
        },
        "CharacterBBehavior.Step.mean": {
            "value": 33339.0,
            "min": 193.0,
            "max": 33339.0,
            "count": 167
        },
        "CharacterBBehavior.Step.sum": {
            "value": 33339.0,
            "min": 193.0,
            "max": 33339.0,
            "count": 167
        },
        "CharacterBBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": -88.26631927490234,
            "min": -129.27635192871094,
            "max": 26.499391555786133,
            "count": 167
        },
        "CharacterBBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": -264.7989501953125,
            "min": -411.461181640625,
            "max": 103.29901885986328,
            "count": 167
        },
        "CharacterBBehavior.Environment.EpisodeLength.mean": {
            "value": 3633.0,
            "min": 63.5,
            "max": 3633.0,
            "count": 51
        },
        "CharacterBBehavior.Environment.EpisodeLength.sum": {
            "value": 3633.0,
            "min": 94.0,
            "max": 3633.0,
            "count": 51
        },
        "CharacterBBehavior.Environment.CumulativeReward.mean": {
            "value": -1504.0600164234638,
            "min": -1603.6399750709534,
            "max": 1403.1000779867172,
            "count": 52
        },
        "CharacterBBehavior.Environment.CumulativeReward.sum": {
            "value": -1504.0600164234638,
            "min": -1603.6399750709534,
            "max": 2414.6800651550293,
            "count": 52
        },
        "CharacterBBehavior.Policy.ExtrinsicReward.mean": {
            "value": -1504.0600164234638,
            "min": -1603.6399750709534,
            "max": 1403.1000779867172,
            "count": 52
        },
        "CharacterBBehavior.Policy.ExtrinsicReward.sum": {
            "value": -1504.0600164234638,
            "min": -1603.6399750709534,
            "max": 2414.6800651550293,
            "count": 52
        },
        "CharacterBBehavior.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 167
        },
        "CharacterBBehavior.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 167
        },
        "CharacterABehavior.Policy.Entropy.mean": {
            "value": 3.029144287109375,
            "min": 2.9378201961517334,
            "max": 3.1669907569885254,
            "count": 141
        },
        "CharacterABehavior.Policy.Entropy.sum": {
            "value": 581.595703125,
            "min": 432.99267578125,
            "max": 813.9166259765625,
            "count": 141
        },
        "CharacterABehavior.Step.mean": {
            "value": 28152.0,
            "min": 193.0,
            "max": 28152.0,
            "count": 141
        },
        "CharacterABehavior.Step.sum": {
            "value": 28152.0,
            "min": 193.0,
            "max": 28152.0,
            "count": 141
        },
        "CharacterABehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 51.52937316894531,
            "min": -85.22834777832031,
            "max": 54.258148193359375,
            "count": 141
        },
        "CharacterABehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 154.58811950683594,
            "min": -340.91339111328125,
            "max": 179.50762939453125,
            "count": 141
        },
        "CharacterABehavior.Environment.EpisodeLength.mean": {
            "value": 725.0,
            "min": 63.5,
            "max": 1871.0,
            "count": 51
        },
        "CharacterABehavior.Environment.EpisodeLength.sum": {
            "value": 725.0,
            "min": 94.0,
            "max": 1871.0,
            "count": 51
        },
        "CharacterABehavior.Environment.CumulativeReward.mean": {
            "value": 953.8999880552292,
            "min": -1599.050048828125,
            "max": 1464.6900143623352,
            "count": 52
        },
        "CharacterABehavior.Environment.CumulativeReward.sum": {
            "value": 953.8999880552292,
            "min": -4785.869955778122,
            "max": 1464.6900143623352,
            "count": 52
        },
        "CharacterABehavior.Policy.ExtrinsicReward.mean": {
            "value": 953.8999880552292,
            "min": -1599.050048828125,
            "max": 1464.6900143623352,
            "count": 52
        },
        "CharacterABehavior.Policy.ExtrinsicReward.sum": {
            "value": 953.8999880552292,
            "min": -4785.869955778122,
            "max": 1464.6900143623352,
            "count": 52
        },
        "CharacterABehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 141
        },
        "CharacterABehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 141
        },
        "CharacterBBehavior.Losses.PolicyLoss.mean": {
            "value": 0.09513751554509832,
            "min": 0.08475735050888034,
            "max": 0.11087829402337472,
            "count": 14
        },
        "CharacterBBehavior.Losses.PolicyLoss.sum": {
            "value": 0.09513751554509832,
            "min": 0.08475735050888034,
            "max": 0.11087829402337472,
            "count": 14
        },
        "CharacterBBehavior.Losses.ValueLoss.mean": {
            "value": 252.33426951398752,
            "min": 252.33426951398752,
            "max": 67704.99196370442,
            "count": 14
        },
        "CharacterBBehavior.Losses.ValueLoss.sum": {
            "value": 252.33426951398752,
            "min": 252.33426951398752,
            "max": 67704.99196370442,
            "count": 14
        },
        "CharacterBBehavior.Policy.LearningRate.mean": {
            "value": 8.070097310000009e-06,
            "min": 8.070097310000009e-06,
            "max": 0.0002789800070066667,
            "count": 14
        },
        "CharacterBBehavior.Policy.LearningRate.sum": {
            "value": 8.070097310000009e-06,
            "min": 8.070097310000009e-06,
            "max": 0.0002789800070066667,
            "count": 14
        },
        "CharacterBBehavior.Policy.Epsilon.mean": {
            "value": 0.10268999999999999,
            "min": 0.10268999999999999,
            "max": 0.19299333333333335,
            "count": 14
        },
        "CharacterBBehavior.Policy.Epsilon.sum": {
            "value": 0.10268999999999999,
            "min": 0.10268999999999999,
            "max": 0.19299333333333335,
            "count": 14
        },
        "CharacterBBehavior.Policy.Beta.mean": {
            "value": 0.00014423100000000023,
            "min": 0.00014423100000000023,
            "max": 0.004650367333333334,
            "count": 14
        },
        "CharacterBBehavior.Policy.Beta.sum": {
            "value": 0.00014423100000000023,
            "min": 0.00014423100000000023,
            "max": 0.004650367333333334,
            "count": 14
        },
        "CharacterABehavior.Losses.PolicyLoss.mean": {
            "value": 0.0965250978382149,
            "min": 0.08464933928917162,
            "max": 0.11076695234320748,
            "count": 13
        },
        "CharacterABehavior.Losses.PolicyLoss.sum": {
            "value": 0.0965250978382149,
            "min": 0.08464933928917162,
            "max": 0.11076695234320748,
            "count": 13
        },
        "CharacterABehavior.Losses.ValueLoss.mean": {
            "value": 7259.163144111633,
            "min": 4128.819995721181,
            "max": 82328.65783691406,
            "count": 13
        },
        "CharacterABehavior.Losses.ValueLoss.sum": {
            "value": 7259.163144111633,
            "min": 4128.819995721181,
            "max": 82328.65783691406,
            "count": 13
        },
        "CharacterABehavior.Policy.LearningRate.mean": {
            "value": 2.894009035333335e-05,
            "min": 2.894009035333335e-05,
            "max": 0.0002789800070066667,
            "count": 13
        },
        "CharacterABehavior.Policy.LearningRate.sum": {
            "value": 2.894009035333335e-05,
            "min": 2.894009035333335e-05,
            "max": 0.0002789800070066667,
            "count": 13
        },
        "CharacterABehavior.Policy.Epsilon.mean": {
            "value": 0.10964666666666667,
            "min": 0.10964666666666667,
            "max": 0.19299333333333335,
            "count": 13
        },
        "CharacterABehavior.Policy.Epsilon.sum": {
            "value": 0.10964666666666667,
            "min": 0.10964666666666667,
            "max": 0.19299333333333335,
            "count": 13
        },
        "CharacterABehavior.Policy.Beta.mean": {
            "value": 0.0004913686666666669,
            "min": 0.0004913686666666669,
            "max": 0.004650367333333334,
            "count": 13
        },
        "CharacterABehavior.Policy.Beta.sum": {
            "value": 0.0004913686666666669,
            "min": 0.0004913686666666669,
            "max": 0.004650367333333334,
            "count": 13
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1761917191",
        "python_version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\49469\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\mlagents-learn config.yaml --run-id=Character1V1Th10",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.12.1+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1761917791"
    },
    "total": 599.4689627999978,
    "count": 1,
    "self": 0.02806359999522101,
    "children": {
        "run_training.setup": {
            "total": 0.15731740000046557,
            "count": 1,
            "self": 0.15731740000046557
        },
        "TrainerController.start_learning": {
            "total": 599.2835818000021,
            "count": 1,
            "self": 0.9992733997059986,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.796879500005161,
                    "count": 1,
                    "self": 11.796879500005161
                },
                "TrainerController.advance": {
                    "total": 586.0644539002969,
                    "count": 33707,
                    "self": 1.1468362993109622,
                    "children": {
                        "env_step": {
                            "total": 525.2254242000781,
                            "count": 33707,
                            "self": 350.9532799001172,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 173.64662020043033,
                                    "count": 33707,
                                    "self": 4.642742600997735,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 169.0038775994326,
                                            "count": 61996,
                                            "self": 169.0038775994326
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.625524099530594,
                                    "count": 33706,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 585.020876199902,
                                            "count": 33706,
                                            "is_parallel": true,
                                            "self": 289.352199200257,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0011027000000467524,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.0007251999995787628,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0003775000004679896,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0003775000004679896
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 295.6675742996449,
                                                    "count": 33706,
                                                    "is_parallel": true,
                                                    "self": 4.3347300989044015,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 4.195513500249945,
                                                            "count": 33706,
                                                            "is_parallel": true,
                                                            "self": 4.195513500249945
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 269.0284841002722,
                                                            "count": 33706,
                                                            "is_parallel": true,
                                                            "self": 269.0284841002722
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 18.108846600218385,
                                                            "count": 67412,
                                                            "is_parallel": true,
                                                            "self": 12.052355902109412,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 6.0564906981089734,
                                                                    "count": 134824,
                                                                    "is_parallel": true,
                                                                    "self": 6.0564906981089734
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 59.692193400907854,
                            "count": 67412,
                            "self": 1.661775301938178,
                            "children": {
                                "process_trajectory": {
                                    "total": 7.216480898976442,
                                    "count": 67412,
                                    "self": 7.216480898976442
                                },
                                "_update_policy": {
                                    "total": 50.813937199993234,
                                    "count": 27,
                                    "self": 10.069303199983551,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 40.74463400000968,
                                            "count": 2595,
                                            "self": 40.74463400000968
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.999980541877449e-07,
                    "count": 1,
                    "self": 6.999980541877449e-07
                },
                "TrainerController._save_models": {
                    "total": 0.42297429999598535,
                    "count": 1,
                    "self": 0.08323039999959292,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.33974389999639243,
                            "count": 2,
                            "self": 0.33974389999639243
                        }
                    }
                }
            }
        }
    }
}