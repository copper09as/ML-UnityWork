{
    "name": "root",
    "gauges": {
        "CharacterABehavior.Policy.Entropy.mean": {
            "value": 2.38020396232605,
            "min": 1.2707499265670776,
            "max": 3.113417625427246,
            "count": 10
        },
        "CharacterABehavior.Policy.Entropy.sum": {
            "value": 456.9991455078125,
            "min": 193.15399169921875,
            "max": 797.034912109375,
            "count": 10
        },
        "CharacterABehavior.Step.mean": {
            "value": 1968.0,
            "min": 192.0,
            "max": 1968.0,
            "count": 10
        },
        "CharacterABehavior.Step.sum": {
            "value": 1968.0,
            "min": 192.0,
            "max": 1968.0,
            "count": 10
        },
        "CharacterABehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 10.436107635498047,
            "min": 1.2571161985397339,
            "max": 37.89839172363281,
            "count": 10
        },
        "CharacterABehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 31.30832290649414,
            "min": 3.771348714828491,
            "max": 127.31916809082031,
            "count": 10
        },
        "CharacterABehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "CharacterABehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "CharacterBBehavior.Policy.Entropy.mean": {
            "value": 1.926918625831604,
            "min": 0.5645187497138977,
            "max": 3.0236339569091797,
            "count": 10
        },
        "CharacterBBehavior.Policy.Entropy.sum": {
            "value": 369.9683837890625,
            "min": 108.38760375976562,
            "max": 774.05029296875,
            "count": 10
        },
        "CharacterBBehavior.Step.mean": {
            "value": 1984.0,
            "min": 192.0,
            "max": 1984.0,
            "count": 10
        },
        "CharacterBBehavior.Step.sum": {
            "value": 1984.0,
            "min": 192.0,
            "max": 1984.0,
            "count": 10
        },
        "CharacterBBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": -20.822885513305664,
            "min": -85.65972137451172,
            "max": -3.7947235107421875,
            "count": 10
        },
        "CharacterBBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": -62.468658447265625,
            "min": -256.9791564941406,
            "max": -11.384170532226562,
            "count": 10
        },
        "CharacterBBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "CharacterBBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "CharacterABehavior.Environment.EpisodeLength.mean": {
            "value": 599.0,
            "min": 599.0,
            "max": 599.0,
            "count": 2
        },
        "CharacterABehavior.Environment.EpisodeLength.sum": {
            "value": 599.0,
            "min": 599.0,
            "max": 599.0,
            "count": 2
        },
        "CharacterABehavior.Environment.CumulativeReward.mean": {
            "value": -48.100006118416786,
            "min": -48.100006118416786,
            "max": 15.349999070167542,
            "count": 2
        },
        "CharacterABehavior.Environment.CumulativeReward.sum": {
            "value": -48.100006118416786,
            "min": -48.100006118416786,
            "max": 15.349999070167542,
            "count": 2
        },
        "CharacterABehavior.Policy.ExtrinsicReward.mean": {
            "value": -48.100006118416786,
            "min": -48.100006118416786,
            "max": 15.349999070167542,
            "count": 2
        },
        "CharacterABehavior.Policy.ExtrinsicReward.sum": {
            "value": -48.100006118416786,
            "min": -48.100006118416786,
            "max": 15.349999070167542,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1761915480",
        "python_version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\49469\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\mlagents-learn config.yaml --run-id=Character1V1Th3",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.12.1+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1761915560"
    },
    "total": 79.27782429999934,
    "count": 1,
    "self": 10.022670400001516,
    "children": {
        "run_training.setup": {
            "total": 0.0756868000025861,
            "count": 1,
            "self": 0.0756868000025861
        },
        "TrainerController.start_learning": {
            "total": 69.17946709999524,
            "count": 1,
            "self": 0.05882309989829082,
            "children": {
                "TrainerController._reset_env": {
                    "total": 12.563215799993486,
                    "count": 1,
                    "self": 12.563215799993486
                },
                "TrainerController.advance": {
                    "total": 55.54609350010287,
                    "count": 2100,
                    "self": 0.06910730025265366,
                    "children": {
                        "env_step": {
                            "total": 54.90701829981117,
                            "count": 2100,
                            "self": 43.21105209963571,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 11.657643700105837,
                                    "count": 2101,
                                    "self": 0.29959929997858126,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 11.358044400127255,
                                            "count": 4202,
                                            "self": 11.358044400127255
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.038322500069625676,
                                    "count": 2099,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 40.31002239996451,
                                            "count": 2099,
                                            "is_parallel": true,
                                            "self": 15.829367199796252,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0021553000042331405,
                                                    "count": 4,
                                                    "is_parallel": true,
                                                    "self": 0.0014476000142167322,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0007076999900164083,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.0007076999900164083
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 24.478499900164024,
                                                    "count": 2099,
                                                    "is_parallel": true,
                                                    "self": 0.2595184002639144,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.26200839996454306,
                                                            "count": 2099,
                                                            "is_parallel": true,
                                                            "self": 0.26200839996454306
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 22.780136800000037,
                                                            "count": 2099,
                                                            "is_parallel": true,
                                                            "self": 22.780136800000037
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1.1768362999355304,
                                                            "count": 4198,
                                                            "is_parallel": true,
                                                            "self": 0.7812364999190322,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.3955998000164982,
                                                                    "count": 8396,
                                                                    "is_parallel": true,
                                                                    "self": 0.3955998000164982
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 0.5699679000390461,
                            "count": 4198,
                            "self": 0.10087030001886887,
                            "children": {
                                "process_trajectory": {
                                    "total": 0.4690976000201772,
                                    "count": 4198,
                                    "self": 0.4690976000201772
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.2000018614344299e-06,
                    "count": 1,
                    "self": 1.2000018614344299e-06
                },
                "TrainerController._save_models": {
                    "total": 1.0113334999987273,
                    "count": 1,
                    "self": 0.07098389999009669,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.9403496000086307,
                            "count": 2,
                            "self": 0.9403496000086307
                        }
                    }
                }
            }
        }
    }
}